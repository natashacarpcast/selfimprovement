{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39ca48b6-e2fa-40de-812e-f8cecff7356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from itertools import combinations\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Tokenizer\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"frequent_itemsets\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54d8d31e-d65d-406b-83c4-f744a49c627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = spark.read.parquet(\"../lab2_clustering/data_and_predictions\")\n",
    "df_text = spark.read.csv(\"../clean_mfd2+liwc.csv\", header= True).select([\"id\", \"cleaned_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ca3d3d1-5fb0-47a6-9009-6d647e2fad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+-----+--------------------+----------+\n",
      "|id_clst|Care_Virtue|Care_Vice|Fairness_Virtue|Fairness_Vice|Loyalty_Virtue|Loyalty_Vice|Authority_Virtue|Authority_Vice|Sanctity_Virtue|Sanctity_Vice|   id|            features|prediction|\n",
      "+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+-----+--------------------+----------+\n",
      "|     15|        0.0|      0.0|            0.0|          0.0|          3.45|         0.0|             0.0|           0.0|            0.0|          0.0|r02b5|[0.50187895826043...|         0|\n",
      "|     16|        2.4|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|r89qc|[-0.1435318624002...|         0|\n",
      "|     20|        0.0|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|rrhg8|           [0.0,0.0]|         0|\n",
      "|     21|        0.0|      0.0|            0.0|          0.0|          2.78|         0.0|             0.0|           0.0|            0.0|          0.0|rtji7|[0.40441260009311...|         0|\n",
      "|     23|       0.61|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|          0.61|            0.0|         0.61|s0ruk|[0.93053629412026...|         0|\n",
      "+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_preds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ede35bad-5cf3-489a-a867-0084f8b86f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   id|        cleaned_text|\n",
      "+-----+--------------------+\n",
      "|hk5r2|i had an appointm...|\n",
      "|iqimz|i created this si...|\n",
      "|pfzt5|hello everyone   ...|\n",
      "|pk714|i grew up with bo...|\n",
      "|q0q8x|i have to ask  wh...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfca0788-4316-48c3-93c6-61bdf4cb475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+--------------------+----------+\n",
      "|     id|        cleaned_text|id_clst|Care_Virtue|Care_Vice|Fairness_Virtue|Fairness_Vice|Loyalty_Virtue|Loyalty_Vice|Authority_Virtue|Authority_Vice|Sanctity_Virtue|Sanctity_Vice|            features|prediction|\n",
      "+-------+--------------------+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+--------------------+----------+\n",
      "|1001497|i am meeting a po...|  79758|       1.03|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|         0.52|[0.12984472686258...|         0|\n",
      "|1001uik|hey  so basically...|  79762|        0.0|      0.0|            0.0|          0.0|           0.0|         0.0|            0.39|           0.0|           0.39|          0.0|[0.27046805673074...|         0|\n",
      "|1002u8v|my life was prett...|  79770|        0.0|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|         1.09|[0.40129571331421...|         0|\n",
      "|1002wwt|welcome to this c...|  79772|       0.73|     0.09|            0.0|         0.05|          0.07|         0.0|             0.4|           0.0|           0.31|         0.19|[0.42975811569798...|         0|\n",
      "|10069yz|so there s this p...|  79785|        0.0|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|           [0.0,0.0]|         0|\n",
      "+-------+--------------------+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_merged = df_text.join(df_preds, on=\"id\", how=\"inner\")\n",
    "df_merged.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24f6e64f-7368-47a1-800f-a0f64ae01426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:==================================>                       (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+--------------------+----------+\n",
      "|     id|        cleaned_text|id_clst|Care_Virtue|Care_Vice|Fairness_Virtue|Fairness_Vice|Loyalty_Virtue|Loyalty_Vice|Authority_Virtue|Authority_Vice|Sanctity_Virtue|Sanctity_Vice|            features|prediction|\n",
      "+-------+--------------------+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+--------------------+----------+\n",
      "|1001497|i am meeting a po...|  79758|       1.03|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|         0.52|[0.12984472686258...|         0|\n",
      "|1001uik|hey  so basically...|  79762|        0.0|      0.0|            0.0|          0.0|           0.0|         0.0|            0.39|           0.0|           0.39|          0.0|[0.27046805673074...|         0|\n",
      "|1002u8v|my life was prett...|  79770|        0.0|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|         1.09|[0.40129571331421...|         0|\n",
      "|1002wwt|welcome to this c...|  79772|       0.73|     0.09|            0.0|         0.05|          0.07|         0.0|             0.4|           0.0|           0.31|         0.19|[0.42975811569798...|         0|\n",
      "|10069yz|so there s this p...|  79785|        0.0|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|           [0.0,0.0]|         0|\n",
      "|10074ch|hi everyone  i pu...|  79791|       2.34|     0.23|            0.0|         0.23|          0.47|         0.0|             0.0|           0.0|            0.0|          0.0|[0.43410081439136...|         0|\n",
      "|1007av9|i had a weird mom...|  79793|        1.3|     0.26|            0.0|          0.0|          0.52|         0.0|            0.52|           0.0|           0.26|          0.0|[0.46892006072914...|         0|\n",
      "|1007px6|i ve been on the ...|  79794|       0.69|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|[-0.0412654086577...|         0|\n",
      "|100bk7z|within the past f...|  79804|       1.56|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|[-0.0932957034308...|         0|\n",
      "|100bnv0|anyone want to sh...|  79805|        6.0|      0.0|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|[-0.3588296417420...|         0|\n",
      "+-------+--------------------+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df0 = df_merged.filter(F.col('prediction') == 0) \\\n",
    "                    .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68130a3a-5262-4097-a52d-aa9ee1aa161b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:===========>                                              (1 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+--------------------+----------+\n",
      "|     id|        cleaned_text|id_clst|Care_Virtue|Care_Vice|Fairness_Virtue|Fairness_Vice|Loyalty_Virtue|Loyalty_Vice|Authority_Virtue|Authority_Vice|Sanctity_Virtue|Sanctity_Vice|            features|prediction|\n",
      "+-------+--------------------+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+--------------------+----------+\n",
      "|1006c2b|self respect is a...|  79786|       2.51|     0.22|           0.25|          0.0|          0.07|         0.0|            2.87|          0.04|           0.22|          0.0|[1.69006669331013...|         1|\n",
      "|100e82k|i have started an...|  79815|        0.0|      0.0|            0.0|         1.85|          5.56|         0.0|             0.0|           0.0|            0.0|         1.85|[4.36351315537381...|         1|\n",
      "|101f5de|imagine this  a h...|  79943|       1.33|      0.0|           0.11|          0.0|           1.1|         0.0|            4.86|          0.11|            0.0|          0.0|[2.61516598373071...|         1|\n",
      "|103va7o|confidence is tru...|  80192|        0.0|      0.0|           1.96|         1.96|           0.0|         0.0|            1.96|           0.0|            0.0|          0.0|[5.80405471562082...|         1|\n",
      "|1057ruy|i know that time ...|  80336|       4.04|     4.04|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|[2.36533586090443...|         1|\n",
      "|1069ej1|i know that i hav...|  80429|       3.85|     1.92|            0.0|          0.0|           0.0|         0.0|             0.0|          0.96|            0.0|          0.0|[2.17712496456848...|         1|\n",
      "|106t82k|i ve already read...|  80488|       4.84|      0.0|           1.61|          0.0|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|[1.21610895952904...|         1|\n",
      "|106uw8r|i lost 16kgs  35l...|  80493|        0.0|     0.63|            0.0|          0.0|           0.0|         0.0|             0.0|           0.0|            2.5|          0.0|[0.95823074863400...|         1|\n",
      "|108xthj|i am returning to...|  80711|        0.0|      0.0|           1.06|         1.06|           0.0|         0.0|             0.0|           0.0|            0.0|          0.0|[2.63773055657778...|         1|\n",
      "|1097wqj|hi  today i ve go...|  80729|        0.0|      0.0|            0.0|          0.0|           0.0|         0.0|            3.61|           0.0|            0.0|          0.0|[1.70690600013031...|         1|\n",
      "+-------+--------------------+-------+-----------+---------+---------------+-------------+--------------+------------+----------------+--------------+---------------+-------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1 = df_merged.filter(F.col('prediction') == 1) \\\n",
    "                    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53658f8-31a0-473e-b0b9-d18f8a3f1476",
   "metadata": {},
   "source": [
    "Get TF IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "690fc6b5-dfa1-4885-ac16-5d434e589f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/30 18:33:43 WARN DAGScheduler: Broadcasting large task binary with size 1740.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/30 18:33:55 WARN DAGScheduler: Broadcasting large task binary with size 1741.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Tokenize\n",
    "tokenizer = Tokenizer(inputCol=\"cleaned_text\", outputCol=\"tokenized\")\n",
    "tokenized_df = tokenizer.transform(df_merged)\n",
    "\n",
    "#Vectorize\n",
    "cv = CountVectorizer(inputCol=\"tokenized\", outputCol=\"vectorized\")\n",
    "model_cv = cv.fit(tokenized_df)\n",
    "vectorized_df = model_cv.transform(tokenized_df)\n",
    "\n",
    "#TF-IDF vectors\n",
    "idf = IDF(inputCol=\"vectorized\", outputCol=\"tf-idf\", minDocFreq = 10)\n",
    "model_idf = idf.fit(vectorized_df)\n",
    "weighted_df = model_idf.transform(vectorized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28bb5c04-e42e-418e-8fcc-b10c8de7c6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2242"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get vocab \n",
    "vocab = model_cv.vocabulary  \n",
    "type(vocab)\n",
    "\n",
    "#Get tf idf vector\n",
    "tfidf_vector =model_idf.idf\n",
    "\n",
    "#Asked ChatGPT \"how can I map the TF IDF vector with it's corresponding words?\" Suggested the following syntax\n",
    "#word_tfidf_pairs = [(vocab[i], tfidf_vector[i]) for i in range(len(tfidf_vector)) if tfidf_vector[i] > 1]\n",
    "#but I prefer to have it as a dictionary so I'll adapt the code \n",
    "\n",
    "#Have a dictionary so I can map numbers to words later\n",
    "word_tfidf_pairs = {tfidf_vector[i]:vocab[i] for i in range(len(tfidf_vector)) if tfidf_vector[i] > 5}\n",
    "len(word_tfidf_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00a4b31d-04fc-450c-9599-6b70ff4548dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/30 19:03:51 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|tf-idf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(157334,[0,1,2,3,5,6,7,10,12,20,21,22,25,29,39,49,50,59,61,66,69,70,83,89,93,118,122,124,143,153,195,197,235,266,273,278,367,387,431,608,802,1083,1230,1268,2024,2146,2429,2442,2484,2792,4474,5178,6299,8213],[0.01757850721482208,1.1320665891083075,0.05604172367442672,0.1551989091522016,0.27459354985847123,0.1370767011155907,0.20457074403249723,0.3600150772284366,1.36083962457471,0.5942865388023151,1.2440410476227983,0.7071937392754202,0.7247300248509352,0.7656837101673328,0.9637694204457763,1.1226710942365306,1.1405234530398667,1.2100373672673261,1.4034394737903786,1.319210674886524,1.3727489659128371,1.37288525727369,1.4824268156310125,1.720736457755432,1.7752958428463488,1.9141245779458456,1.928182836503122,1.9029979704598516,2.083841007304084,2.170879013380667,2.367251530300651,2.467628045886258,2.5826372173442453,2.844803481613089,5.552589359683256,2.7861100637074983,3.1966912298925236,3.157364065716987,7.046682684198246,3.63598347853537,4.068862725696477,4.39844594180497,4.617540904593179,4.838113947423106,5.336264926942774,5.376522446824496,11.199331996277412,5.788022325094184,5.86545937180105,5.879769667113992,6.79229262607734,6.834183567786501,7.174943056419333,7.650475727144214])|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weighted_df.select([\"tf-idf\"]).show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e39dc22-ad83-449d-bb6c-ffdabf9078ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Function to filter words based on TF-IDF score\n",
    "def filter_words_by_tfidf(tfidf_vector):\n",
    "    tfidf_vector = tfidf_vector.toArray()\n",
    "    return tfidf_vector[0]\n",
    "                        \n",
    "                        \n",
    "filter_words_udf = F.udf(lambda vector, indices: filter_words_by_tfidf(vector, indices, vocab, tfidf_threshold), \n",
    "                          ArrayType(StringType()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7406072b-7f80-44f2-a74e-4f794cda3679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.linalg.DenseVector"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07f5f878-7bd1-4c7d-86a7-8fdab9c008b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_representation = tfidf_vector.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "42570606-e6bb-43b6-a92a-ea791826208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00219731, 0.18867776, 0.05604172, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "241c9037-9c50-43ac-9f7d-f807dedea5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words_df = weighted_df.withColumn(\"tokenized\", filter_words_udf(F.col(\"tf-idf\"), F.col(\"vectorized\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cfd2b829-b114-4053-aa36-5bbff2986883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:>                                                         (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/30 19:14:50 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/30 19:14:51 ERROR Executor: Exception in task 0.0 in stage 79.0 (TID 198)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/scratch/local/jobs/24976501/ipykernel_2543762/357167070.py\", line 7, in <lambda>\n",
      "NameError: name 'tfidf_threshold' is not defined\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:552)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:505)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:832)\n",
      "24/10/30 19:14:51 WARN TaskSetManager: Lost task 0.0 in stage 79.0 (TID 198) (midway3-0081.rcc.local executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/scratch/local/jobs/24976501/ipykernel_2543762/357167070.py\", line 7, in <lambda>\n",
      "NameError: name 'tfidf_threshold' is not defined\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:552)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:505)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:832)\n",
      "\n",
      "24/10/30 19:14:51 ERROR TaskSetManager: Task 0 in stage 79.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/scratch/local/jobs/24976501/ipykernel_2543762/357167070.py\", line 7, in <lambda>\nNameError: name 'tfidf_threshold' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfiltered_words_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/software/spark-3.3.2-el8-x86_64/python/pyspark/sql/dataframe.py:606\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/software/spark-3.3.2-el8-x86_64/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/software/spark-3.3.2-el8-x86_64/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/scratch/local/jobs/24976501/ipykernel_2543762/357167070.py\", line 7, in <lambda>\nNameError: name 'tfidf_threshold' is not defined\n"
     ]
    }
   ],
   "source": [
    "filtered_words_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b27383-b121-4780-82cc-8e6a3905d442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
