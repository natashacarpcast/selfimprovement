{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc0afd78-48a4-475f-9270-748655b01dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "from pyspark.sql import SparkSession\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8abdf9-c782-45e3-83f5-dee81d128816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/11 12:36:11 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"community detection\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d04f82-3fcc-4702-8e9a-dcc55651a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "950a6f11-4f24-4a51-9f9e-447e4824cdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|age2| name|\n",
      "+----+-----+\n",
      "|   2|Alice|\n",
      "|   5|  Bob|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n",
    "df.withColumnRenamed('age', 'age2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8712201-abc1-4861-9219-3450abe6bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nodes\n",
    "nodes_df = spark.read.csv(\"../data/network-topics-morality/finalized_nodes_topics_morality_net.csv\", \n",
    "                         header=True).withColumnRenamed('_c0', 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23eadabe-954a-4016-959b-f2e87322f922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/11 13:07:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , node, category\n",
      " Schema: _c0, node, category\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/natashacarpcast/Documents/selfimprovement/data/network-topics-morality/finalized_nodes_topics_morality_net.csv\n",
      "+---+------------+----------+\n",
      "| id|        node|  category|\n",
      "+---+------------+----------+\n",
      "|  0|      online|    topic3|\n",
      "|  1|  misogynist|liwc_moral|\n",
      "|  2|  productive|    topic1|\n",
      "|  3|      absurd|liwc_moral|\n",
      "|  4|conversation|    topic7|\n",
      "+---+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a3d3286-f6b7-49a8-9614-7a4f805a86d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, src: string, dst: string, weight: string]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load edges\n",
    "edges_df = spark.read.csv(\"../data/network-topics-morality/filtered_edges_topics_morality_net.csv\", \n",
    "                         header=True).withColumnRenamed(\"node1_norm\", \"src\")\n",
    "\n",
    "edges_df = edges_df.withColumnRenamed(\"node2_norm\", \"dst\")\n",
    "\n",
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b813ec1c-9110-4ba3-95c8-5c6d1cffc759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/spark-3.3.2-el8-x86_64/python/pyspark/sql/dataframe.py:148: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Create GraphFrame\n",
    "g = GraphFrame(nodes_df, edges_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af631a86-235a-40d6-b1df-0a8d3ed2ec66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphFrame(v:[id: string, node: string ... 1 more field], e:[src: string, dst: string ... 2 more fields])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d9df0e3-f373-4310-b4ae-1f9b91b35f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/11 13:12:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , node, category\n",
      " Schema: _c0, node, category\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/natashacarpcast/Documents/selfimprovement/data/network-topics-morality/finalized_nodes_topics_morality_net.csv\n",
      "+---+------------+----------+\n",
      "| id|        node|  category|\n",
      "+---+------------+----------+\n",
      "|  0|      online|    topic3|\n",
      "|  1|  misogynist|liwc_moral|\n",
      "|  2|  productive|    topic1|\n",
      "|  3|      absurd|liwc_moral|\n",
      "|  4|conversation|    topic7|\n",
      "|  5|    pettiest|liwc_moral|\n",
      "|  6|   character|    topic1|\n",
      "|  7|  accusation|liwc_moral|\n",
      "|  8|     dissing|liwc_moral|\n",
      "|  9|    elitists|liwc_moral|\n",
      "| 10|    outlawed|liwc_moral|\n",
      "| 11|   grandiose|liwc_moral|\n",
      "| 12|        evil|liwc_moral|\n",
      "| 13| disapproved|liwc_moral|\n",
      "| 14|    buffoons|liwc_moral|\n",
      "| 15|  admonishes|liwc_moral|\n",
      "| 16|   instagram|    topic2|\n",
      "| 17| absurdities|liwc_moral|\n",
      "| 18|        lewd|liwc_moral|\n",
      "| 19|   worthless|liwc_moral|\n",
      "+---+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.vertices.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa45ff83-4ac1-4c0c-ab5a-5a1bfac22d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/11 13:12:33 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , node1_norm, node2_norm, weight\n",
      " Schema: _c0, node1_norm, node2_norm, weight\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/natashacarpcast/Documents/selfimprovement/data/network-topics-morality/filtered_edges_topics_morality_net.csv\n",
      "+---+------------+--------+------+\n",
      "|_c0|         src|     dst|weight|\n",
      "+---+------------+--------+------+\n",
      "|  0|  depression|   woman|  2390|\n",
      "|  1|    generous|   loyal|     8|\n",
      "|  2|        body|     job|  7010|\n",
      "|  3|     college|  family|  7990|\n",
      "|  4|       fault| student|   266|\n",
      "|  5|       drink| hobbies|  1441|\n",
      "|  6|     healthy|   voice|   838|\n",
      "|  7|        read|  worthy|  1136|\n",
      "|  8|       money|  social|  9445|\n",
      "|  9|  productive|specific|   660|\n",
      "| 10|        male|    talk|  3761|\n",
      "| 11|   happiness|   wrong|  2792|\n",
      "| 12|     deserve| respect|  1928|\n",
      "| 13|conversation| emotion|  2952|\n",
      "| 14|        girl| respect|  3490|\n",
      "| 15|      family|    high|  8198|\n",
      "| 16|        high|    move|  7632|\n",
      "| 17|        move|    pain|  3958|\n",
      "| 18|        hair|   noble|    10|\n",
      "| 19|        girl|   weird|  4132|\n",
      "+---+------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76896aac-d9c7-4b78-8d45-aac9c8b4a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create undirected edges\n",
    "undirected_edges = g.edges.union(g.edges.withColumnRenamed(\"src\", \"dst\").withColumnRenamed(\"dst\", \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b3f2532-3a9b-4f70-9e1e-493ea302c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/11 13:17:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , node1_norm, node2_norm, weight\n",
      " Schema: _c0, node1_norm, node2_norm, weight\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/natashacarpcast/Documents/selfimprovement/data/network-topics-morality/filtered_edges_topics_morality_net.csv\n",
      "+---+----------+-------+------+\n",
      "|_c0|       src|    dst|weight|\n",
      "+---+----------+-------+------+\n",
      "|  0|depression|  woman|  2390|\n",
      "|  1|  generous|  loyal|     8|\n",
      "|  2|      body|    job|  7010|\n",
      "|  3|   college| family|  7990|\n",
      "|  4|     fault|student|   266|\n",
      "+---+----------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undirected_edges.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de14ce-5795-4769-93c5-6973b410a0a8",
   "metadata": {},
   "source": [
    "Check it is undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8aa13060-acb3-4d6e-b802-ea6488c86119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04d1ce21-b8ce-4f35-bc5c-f1eb77a96882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116002"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undirected_edges.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0669e98-7ece-4f5e-b1d8-af379053fd4d",
   "metadata": {},
   "source": [
    "Create new graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ccf2455-152b-4424-b330-bfa3faff675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GraphFrame(g.vertices, undirected_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd9cf2b6-df31-4255-9406-c44495493005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphFrame(v:[id: string, node: string ... 1 more field], e:[src: string, dst: string ... 2 more fields])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8aa22cb-b120-4ec7-a973-e3e7e366980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Louvain https://github.com/DS4AI-UPB/CommunityDetection-DataframesSpark/blob/main/communitydetection_graphframes.py\n",
    "def get_graph_vertices_list(g):\n",
    "    vertices = []\n",
    "    dataframe_vertices = g.vertices.select(\"id\").collect()\n",
    "    for row in dataframe_vertices:\n",
    "        vertices.append(row.id)\n",
    "    return vertices\n",
    "\n",
    "def get_graph_edges_list(g):\n",
    "    edges = []\n",
    "    dataframe_edges = g.edges.select(\"src\",\"dst\",\"weight\").collect()\n",
    "    for row in dataframe_edges:\n",
    "        edges.append((row.src, row.dst,row.weight))\n",
    "    return edges\n",
    "\n",
    "#Modified to suit my data\n",
    "def get_graph_weights_sum(g):\n",
    "    return g.edges.agg(F.sum('weight')).collect()[0][0]\n",
    "\n",
    "def get_nodes_degrees(g):\n",
    "    nodes = get_graph_vertices_list(g)\n",
    "    in_degree = {}\n",
    "    out_degree = {}\n",
    "    idx = 0\n",
    "    for node in nodes:\n",
    "        out_degree[node] = g.edges.select(\"weight\").where(\"src=={}\".format(node)).groupBy().sum().collect()[0][\"sum(weight)\"]\n",
    "        in_degree[node] = g.edges.select(\"weight\").where(\"dst=={}\".format(node)).groupBy().sum().collect()[0][\"sum(weight)\"]\n",
    "        if in_degree[node] == None:\n",
    "            in_degree[node] = 0\n",
    "        if out_degree[node] == None:\n",
    "            out_degree[node] = 0\n",
    "        idx += 1  \n",
    "    return in_degree, out_degree\n",
    "\n",
    "def get_degree_to_adjacent_communities(g, node, community_of):\n",
    "    degree = {}\n",
    "    neighbors = list(map(lambda x: (x.dst,x.weight), g.edges.select(\"dst\", \"weight\").where(\"src=={}\".format(node)).collect()))\n",
    "    for (neighbor, weight) in neighbors:\n",
    "        adjacent_community = community_of[neighbor]\n",
    "        if adjacent_community not in degree:\n",
    "            degree[adjacent_community] = 0\n",
    "        degree[adjacent_community] += weight\n",
    "    return degree\n",
    "\n",
    "def get_global_community(g, node):\n",
    "    enclosed_nodes = set(list(g.vertices.select(\"community\").where(\"id=={}\".format(node)).collect()[0].community))\n",
    "    return enclosed_nodes\n",
    "\n",
    "def calc_modularity(g, partition, m):\n",
    "    m = get_graph_weights_sum(g)\n",
    "    modularity = 0\n",
    "    in_degree, out_degree = get_nodes_degrees(g)\n",
    "    edges = get_graph_edges_list(g)\n",
    "    community_of = {}\n",
    "    for idx, part in enumerate(partition):\n",
    "        for node in part:\n",
    "            community_of[node] = idx\n",
    "    for edge in edges:\n",
    "        src, dst = edge[0], edge[1]\n",
    "        community_src, community_dst = community_of[src], community_of[dst]\n",
    "        if community_src != community_dst:\n",
    "            continue\n",
    "        weight = edge[2]\n",
    "        modularity += (weight/2*m) - (in_degree[src]*out_degree[dst])/(2*m**2)\n",
    "    return modularity\n",
    "\n",
    "def first_phase_louvain(g, global_partition, m, gamma):\n",
    "    community_of = {node: idx for idx, node in enumerate(get_graph_vertices_list(g))}\n",
    "    nodes = get_graph_vertices_list(g)\n",
    "    new_partition = [set() for node in nodes]\n",
    "    (in_degree, out_degree), (community_in, community_out) = get_nodes_degrees(g), get_nodes_degrees(g)\n",
    "    while True:\n",
    "        stop = True\n",
    "        for node in nodes:\n",
    "            chosen_comunity = community_of[node]\n",
    "            max_improvement = 0\n",
    "            community_in[chosen_comunity] -= in_degree[node]\n",
    "            community_out[chosen_comunity] -= out_degree[node]\n",
    "            degree_to_adj_communities = get_degree_to_adjacent_communities(g, node, community_of)\n",
    "            for (adjacent_community, adjacent_degree) in degree_to_adj_communities.items():\n",
    "                improvement = (adjacent_degree - gamma * (in_degree[node] * community_out[adjacent_community] + out_degree[node] * community_in[adjacent_community])/m)\n",
    "                if improvement > max_improvement:\n",
    "                    max_improvement = improvement\n",
    "                    chosen_comunity = adjacent_community\n",
    "            community_in[chosen_comunity] += in_degree[node]\n",
    "            community_out[chosen_comunity] += out_degree[node]\n",
    "            if chosen_comunity != community_of[node]: \n",
    "                community_of[node] = chosen_comunity\n",
    "                stop = False\n",
    "        if stop:\n",
    "            break\n",
    "    for node, community in community_of.items():\n",
    "        new_partition[community].add(node)\n",
    "        global_community = get_global_community(g, node)               \n",
    "        global_partition[node].difference_update(global_community)\n",
    "        global_partition[community].update(global_community)\n",
    "    new_partition = list(filter(lambda x: x != set(), new_partition))\n",
    "    global_partition = list(filter(lambda x: x != set(), global_partition))\n",
    "\n",
    "    return global_partition, new_partition, stop\n",
    "\n",
    "def second_phase_louvain(g, new_partition):\n",
    "    community_of = {}\n",
    "    vertices_columns = [\"name\", \"id\", \"community\"]\n",
    "    new_vertices = []\n",
    "    for idx, partition in enumerate(new_partition):\n",
    "        enclosed_nodes = []\n",
    "        for node in partition:\n",
    "            community_of[node] = idx\n",
    "            sub_nodes = g.vertices.select(\"community\").where(\"id=={}\".format(node)).collect()[0].community\n",
    "            enclosed_nodes += sub_nodes\n",
    "        new_vertices.append((str(idx), idx, enclosed_nodes))\n",
    "    \n",
    "    edges = get_graph_edges_list(g)\n",
    "    weights_between_communities = {}\n",
    "    for edge in edges:\n",
    "        src, dst, weight = edge[0], edge[1], edge[2]\n",
    "        community_src, community_dst = community_of[src], community_of[dst]\n",
    "        if not (community_src, community_dst) in weights_between_communities:\n",
    "            weights_between_communities[(community_src, community_dst)] = 0\n",
    "        weights_between_communities[(community_src, community_dst)] += weight\n",
    "    \n",
    "    new_edges = []\n",
    "    edges_columns = [\"src\", \"dst\", \"relationship\", \"weight\"]\n",
    "    for k, v in weights_between_communities.items():\n",
    "        new_edges.append((k[0], k[1], \"friend\", v))\n",
    "    \n",
    "    v = ss.createDataFrame(new_vertices, vertices_columns)\n",
    "    e = ss.createDataFrame(new_edges, edges_columns)\n",
    "    new_g = GraphFrame(v, e)\n",
    "    return new_g\n",
    "\n",
    "def run_louvain(g, gamma=0.05): \n",
    "    m = get_graph_weights_sum(g)\n",
    "    communities = [{node} for node in get_graph_vertices_list(g)]\n",
    "    current_modularity = calc_modularity(g, communities, m)\n",
    "    threshold=0.0000001\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        communities, next_partition, stop = first_phase_louvain(g, communities, m, gamma)\n",
    "        if stop:\n",
    "            break\n",
    "\n",
    "        new_mod = calc_modularity(g, next_partition, m)\n",
    "        if new_mod - current_modularity <= threshold:\n",
    "            break\n",
    "\n",
    "        current_modularity = new_mod\n",
    "        g = second_phase_louvain(g, next_partition)\n",
    "        iteration += 1\n",
    "    print(iteration)\n",
    "    for community in communities:\n",
    "        print(sorted(community))\n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "177e994a-7499-477a-a9ca-25d4f9b0a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/11 13:34:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c0\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/natashacarpcast/Documents/selfimprovement/data/network-topics-morality/finalized_nodes_topics_morality_net.csv\n",
      "24/12/11 13:34:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c0\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/natashacarpcast/Documents/selfimprovement/data/network-topics-morality/finalized_nodes_topics_morality_net.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "sum(weight)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/software/spark-3.3.2-el8-x86_64/python/pyspark/sql/types.py:1884\u001b[0m, in \u001b[0;36mRow.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1882\u001b[0m     \u001b[38;5;66;03m# it will be slow when it has many fields,\u001b[39;00m\n\u001b[1;32m   1883\u001b[0m     \u001b[38;5;66;03m# but this will not be used in normal cases\u001b[39;00m\n\u001b[0;32m-> 1884\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__fields__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Row, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(idx)\n",
      "\u001b[0;31mValueError\u001b[0m: 'sum(weight)' is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_louvain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36mrun_louvain\u001b[0;34m(g, gamma)\u001b[0m\n\u001b[1;32m    134\u001b[0m m \u001b[38;5;241m=\u001b[39m get_graph_weights_sum(g)\n\u001b[1;32m    135\u001b[0m communities \u001b[38;5;241m=\u001b[39m [{node} \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m get_graph_vertices_list(g)]\n\u001b[0;32m--> 136\u001b[0m current_modularity \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_modularity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommunities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0000001\u001b[39m\n\u001b[1;32m    138\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36mcalc_modularity\u001b[0;34m(g, partition, m)\u001b[0m\n\u001b[1;32m     50\u001b[0m m \u001b[38;5;241m=\u001b[39m get_graph_weights_sum(g)\n\u001b[1;32m     51\u001b[0m modularity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 52\u001b[0m in_degree, out_degree \u001b[38;5;241m=\u001b[39m \u001b[43mget_nodes_degrees\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m edges \u001b[38;5;241m=\u001b[39m get_graph_edges_list(g)\n\u001b[1;32m     54\u001b[0m community_of \u001b[38;5;241m=\u001b[39m {}\n",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36mget_nodes_degrees\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     24\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m---> 26\u001b[0m     out_degree[node] \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc==\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum(weight)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m     in_degree[node] \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39medges\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdst==\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(node))\u001b[38;5;241m.\u001b[39mgroupBy()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum(weight)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m in_degree[node] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/software/spark-3.3.2-el8-x86_64/python/pyspark/sql/types.py:1889\u001b[0m, in \u001b[0;36mRow.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(item)\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m-> 1889\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(item)\n",
      "\u001b[0;31mValueError\u001b[0m: sum(weight)"
     ]
    }
   ],
   "source": [
    "run_louvain(g, gamma=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f74f00-1b8b-4fd6-af73-f99884262f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_weights_sum(g):\n",
    "    dataframe_weights_sum = g.edges.select('weight').groupBy().sum().collect()\n",
    "    return dataframe_weights_sum[0][\"sum(weight)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c17dac0c-bd2f-46c9-be3d-ec0877ae5e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row()]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges.select('weight').groupBy().sum().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62f738aa-cbbc-4482-82fd-d78019c3cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|weight|\n",
      "+------+\n",
      "|  2390|\n",
      "|     8|\n",
      "|  7010|\n",
      "|  7990|\n",
      "|   266|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.edges.select('weight').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1727d92e-7b02-4bf4-98a1-07ae41bd1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weight = g.edges.agg(F.sum('weight')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33f2d681-001a-4013-817c-fffc4c2cddcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85892490.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f20f9a-718c-4e89-832c-6bd9d3adf723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
